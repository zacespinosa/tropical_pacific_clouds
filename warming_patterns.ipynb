{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I we examine the pattern of warming associated with the largest 30 year trend in SST# for the first 150 years of a PiControl simulation for each CMIP6 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xcdat as xc\n",
    "import xskillscore as xscore\n",
    "\n",
    "from glob import glob\n",
    "from typing import Tuple, Dict, Union, Optional, Any, Callable, Iterable, Sequence, cast\n",
    "\n",
    "# Ignore xarray warnings (bad practice)\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(era: str = \"cmip6\") -> Tuple[xr.Dataset, Union[xr.Dataset, Dict], Union[xr.Dataset, Dict], Union[xr.Dataset, Dict]]:\n",
    "    models = []\n",
    "    for model_path in glob(f\"data/sharp/{era}/SWCF_*.nc\"):\n",
    "            model_name = model_path.split(\"/\")[-1].split(\".\")[0][5:]\n",
    "            models.append(model_name)\n",
    "\n",
    "    ################## Load SST Sharp Trends and SST Sharp #######################\n",
    "    tos_sharp = {}\n",
    "    for model in models:\n",
    "        try: \n",
    "            tos_sharp[model] = xr.open_dataset(f\"data/sharp/{era}/SSTsharp_{model}.nc\") \n",
    "            models.append(model)\n",
    "        except Exception as e:\n",
    "            print(model, e)\n",
    "\n",
    "    ds_tos_sharp = xr.concat(list(tos_sharp.values()), dim='model')\n",
    "    # Set the coordinates for the 'model' dimension\n",
    "    ds_tos_sharp = ds_tos_sharp.assign_coords(model=models)\n",
    "\n",
    "    return  ds_tos_sharp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/file_manager.py:209\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key]\n\u001b[1;32m    210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/lru_cache.py:55\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m---> 55\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache[key]\n\u001b[1;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/home/espinosa10/tropical_pacific_clouds/data/sharp/cmip6/SSTsharp_INM-CM4-8.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '969aa282-352c-477f-b1f6-3568ee7d0417']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ds_tos_sharp_cmip6 \u001b[39m=\u001b[39m load_datasets(era\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcmip6\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m ds_tos_sharp_cmip6\n",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36mload_datasets\u001b[0;34m(era)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m     10\u001b[0m     \u001b[39mtry\u001b[39;00m: \n\u001b[0;32m---> 11\u001b[0m         tos_sharp[model] \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39mopen_dataset(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/sharp/\u001b[39m\u001b[39m{\u001b[39;00mera\u001b[39m}\u001b[39;00m\u001b[39m/SSTsharp_\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m.nc\u001b[39m\u001b[39m\"\u001b[39m) \n\u001b[1;32m     12\u001b[0m         models\u001b[39m.\u001b[39mappend(model)\n\u001b[1;32m     13\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/api.py:539\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m decoders \u001b[39m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    528\u001b[0m     decode_cf,\n\u001b[1;32m    529\u001b[0m     open_backend_dataset_parameters\u001b[39m=\u001b[39mbackend\u001b[39m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    535\u001b[0m     decode_coords\u001b[39m=\u001b[39mdecode_coords,\n\u001b[1;32m    536\u001b[0m )\n\u001b[1;32m    538\u001b[0m overwrite_encoded_chunks \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39moverwrite_encoded_chunks\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 539\u001b[0m backend_ds \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mopen_dataset(\n\u001b[1;32m    540\u001b[0m     filename_or_obj,\n\u001b[1;32m    541\u001b[0m     drop_variables\u001b[39m=\u001b[39mdrop_variables,\n\u001b[1;32m    542\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecoders,\n\u001b[1;32m    543\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    544\u001b[0m )\n\u001b[1;32m    545\u001b[0m ds \u001b[39m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    546\u001b[0m     backend_ds,\n\u001b[1;32m    547\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    556\u001b[0m )\n\u001b[1;32m    557\u001b[0m \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:572\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen_dataset\u001b[39m(\n\u001b[1;32m    552\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    553\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m     autoclose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m ):\n\u001b[1;32m    571\u001b[0m     filename_or_obj \u001b[39m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 572\u001b[0m     store \u001b[39m=\u001b[39m NetCDF4DataStore\u001b[39m.\u001b[39mopen(\n\u001b[1;32m    573\u001b[0m         filename_or_obj,\n\u001b[1;32m    574\u001b[0m         mode\u001b[39m=\u001b[39mmode,\n\u001b[1;32m    575\u001b[0m         \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m,\n\u001b[1;32m    576\u001b[0m         group\u001b[39m=\u001b[39mgroup,\n\u001b[1;32m    577\u001b[0m         clobber\u001b[39m=\u001b[39mclobber,\n\u001b[1;32m    578\u001b[0m         diskless\u001b[39m=\u001b[39mdiskless,\n\u001b[1;32m    579\u001b[0m         persist\u001b[39m=\u001b[39mpersist,\n\u001b[1;32m    580\u001b[0m         lock\u001b[39m=\u001b[39mlock,\n\u001b[1;32m    581\u001b[0m         autoclose\u001b[39m=\u001b[39mautoclose,\n\u001b[1;32m    582\u001b[0m     )\n\u001b[1;32m    584\u001b[0m     store_entrypoint \u001b[39m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    585\u001b[0m     \u001b[39mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:376\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    370\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    371\u001b[0m     clobber\u001b[39m=\u001b[39mclobber, diskless\u001b[39m=\u001b[39mdiskless, persist\u001b[39m=\u001b[39mpersist, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m\n\u001b[1;32m    372\u001b[0m )\n\u001b[1;32m    373\u001b[0m manager \u001b[39m=\u001b[39m CachingFileManager(\n\u001b[1;32m    374\u001b[0m     netCDF4\u001b[39m.\u001b[39mDataset, filename, mode\u001b[39m=\u001b[39mmode, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    375\u001b[0m )\n\u001b[0;32m--> 376\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(manager, group\u001b[39m=\u001b[39mgroup, mode\u001b[39m=\u001b[39mmode, lock\u001b[39m=\u001b[39mlock, autoclose\u001b[39m=\u001b[39mautoclose)\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:323\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group \u001b[39m=\u001b[39m group\n\u001b[1;32m    322\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m mode\n\u001b[0;32m--> 323\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mds\u001b[39m.\u001b[39mdata_model\n\u001b[1;32m    324\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filename \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mds\u001b[39m.\u001b[39mfilepath()\n\u001b[1;32m    325\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_remote \u001b[39m=\u001b[39m is_remote_uri(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filename)\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:385\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    384\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mds\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 385\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_acquire()\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:379\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_acquire\u001b[39m(\u001b[39mself\u001b[39m, needs_lock\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 379\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_manager\u001b[39m.\u001b[39macquire_context(needs_lock) \u001b[39mas\u001b[39;00m root:\n\u001b[1;32m    380\u001b[0m         ds \u001b[39m=\u001b[39m _nc4_require_group(root, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode)\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/file_manager.py:197\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m@contextlib\u001b[39m\u001b[39m.\u001b[39mcontextmanager\n\u001b[1;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39macquire_context\u001b[39m(\u001b[39mself\u001b[39m, needs_lock\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    196\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     file, cached \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_acquire_with_cache_info(needs_lock)\n\u001b[1;32m    198\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m         \u001b[39myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/file_manager.py:215\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    213\u001b[0m     kwargs \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    214\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode\n\u001b[0;32m--> 215\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_opener(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    217\u001b[0m     \u001b[39m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2486\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2011\u001b[0m, in \u001b[0;36mgenexpr\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2011\u001b[0m, in \u001b[0;36mgenexpr\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/netCDF4/utils.py:34\u001b[0m, in \u001b[0;36m_find_dim\u001b[0;34m(grp, dimname)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sortbylist\u001b[39m(A,B):\n\u001b[1;32m     31\u001b[0m     \u001b[39m# sort one list (A) using the values from another list (B)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m [A[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(A)), key\u001b[39m=\u001b[39mB\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m)]\n\u001b[0;32m---> 34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_find_dim\u001b[39m(grp, dimname):\n\u001b[1;32m     35\u001b[0m     \u001b[39m# find Dimension instance given group and name.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[39m# look in current group, and parents.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     group \u001b[39m=\u001b[39m grp\n\u001b[1;32m     38\u001b[0m     dim \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds_tos_sharp_cmip6 = load_datasets(era=\"cmip6\")\n",
    "ds_tos_sharp_cmip6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_trend(data: xr.Dataset, model: str = \"\", window: int = 12*30, step: int = 12) -> xr.Dataset:\n",
    "    \"\"\"Calculate the rolling gradient of a dataset\n",
    "\n",
    "    Args:\n",
    "        data (xr.Dataset): _description_\n",
    "        window (int, optional): _description_. Defaults to 120*30.\n",
    "        step (int, optional): _description_. Defaults to 12.\n",
    "\n",
    "    Returns:\n",
    "        np.array: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate SSTd = SSTsharp (warm) - SSTflat (cold)\n",
    "    SSTd = data[\"sharp\"] - data[\"flat\"]\n",
    "    SSTsharp = data[\"sharp\"] \n",
    "    SSTflat = data[\"flat\"]\n",
    "    ntime = SSTd.shape[0]\n",
    "\n",
    "    SSTd_trend = np.zeros(int(np.ceil(np.ceil((ntime - window)/12))))\n",
    "    SSTsharp_trend = np.zeros(int(np.ceil(np.ceil((ntime - window)/12))))\n",
    "    SSTflat_trend = np.zeros(int(np.ceil(np.ceil((ntime - window)/12))))\n",
    "    SSTd_trend.fill(np.nan)\n",
    "    SSTsharp_trend.fill(np.nan)\n",
    "    SSTflat_trend.fill(np.nan)\n",
    "\n",
    "    # Calculate rolling trend of SSTd\n",
    "    time_idx = xr.DataArray(np.arange(window), dims=(\"time\"))\n",
    "    for j, i in enumerate(range(0, ntime - window, step)):\n",
    "        slice_SSTd = SSTd.isel(time=slice(i, int(i+window)))\n",
    "        slice_SSTsharp = SSTsharp.isel(time=slice(i, int(i+window)))\n",
    "        slice_SSTflat = SSTflat.isel(time=slice(i, int(i+window)))\n",
    "        SSTd_trend[j] = xscore.linslope(time_idx, slice_SSTd, dim='time', skipna=True).values\n",
    "        SSTsharp_trend[j] = xscore.linslope(time_idx, slice_SSTsharp, dim='time', skipna=True).values\n",
    "        SSTflat_trend[j] = xscore.linslope(time_idx, slice_SSTflat, dim='time', skipna=True).values\n",
    "    \n",
    "    # Convert SSTd trend and SSTd to xr.DataArray\n",
    "    SSTd_trend = xr.DataArray(SSTd_trend, dims=(\"time\"), coords={\"time\": np.arange(SSTd_trend.shape[0])})\n",
    "    SSTsharp_trend = xr.DataArray(SSTsharp_trend, dims=(\"time\"), coords={\"time\": np.arange(SSTd_trend.shape[0])})\n",
    "    SSTflat_trend = xr.DataArray(SSTflat_trend, dims=(\"time\"), coords={\"time\": np.arange(SSTd_trend.shape[0])})\n",
    "    # Convert SSTd to xr.DataArray\n",
    "    SSTd = xr.DataArray(SSTd, dims=(\"time\"), coords={\"time\": np.arange(SSTd.shape[0])})\n",
    "    SSTsharp= xr.DataArray(SSTsharp, dims=(\"time\"), coords={\"time\": np.arange(SSTd.shape[0])})\n",
    "    SSTflat = xr.DataArray(SSTflat, dims=(\"time\"), coords={\"time\": np.arange(SSTd.shape[0])})\n",
    "    # Combine SSTd and SSTd_trend into xr.Dataset\n",
    "    ds = xr.Dataset({\"SSTd\": SSTd, \"SSTd_trend\": SSTd_trend, \"SSTsharp\": SSTsharp, \"SSTsharp_trend\": SSTsharp_trend, \"SSTflat\": SSTflat, \"SSTflat_trend\": SSTflat_trend})\n",
    "\n",
    "    # Sanity plot of SSTd and SSTd_trend\n",
    "    # sanity_rolling_trend(window=window, sharp=data[\"sharp\"], flat=data[\"flat\"], trend=SSTd_trend*window, raw=SSTd, model=model) \n",
    "\n",
    "    return ds\n",
    "\n",
    "# Load SST Sharp Trend\n",
    "def get_rolling_trend(ds_tos_sharp):\n",
    "    tos_trends_sharp = {}\n",
    "\n",
    "    for model in ds_tos_sharp.model.values:\n",
    "        try: \n",
    "            tos_trends_sharp[model] = calculate_rolling_trend(ds_tos_sharp.sel(model=model))\n",
    "        except Exception as e:\n",
    "            print(model, e)\n",
    "\n",
    "    ds_tos_trends_sharp = xr.concat(list(tos_trends_sharp.values()), dim='model')\n",
    "    ds_tos_trends_sharp = ds_tos_trends_sharp.assign_coords(model=list(tos_trends_sharp.keys()))\n",
    "    return ds_tos_trends_sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tos_trends_sharp_cmip6 = get_rolling_trend(ds_tos_sharp_cmip6)\n",
    "ds_tos_trends_sharp_cmip6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
