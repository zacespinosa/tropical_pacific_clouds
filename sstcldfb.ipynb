{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import xcdat as xc\n",
    "import xsearch as xs\n",
    "import xskillscore as xscore\n",
    "\n",
    "from glob import glob \n",
    "from typing import List, Tuple, Dict, Union, Optional, Any, Callable, Iterable, Sequence, cast\n",
    "\n",
    "# Ignore xarray warnings (bad practice)\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting era:  CMIP5\n",
      "Starting variable:  tos\n",
      "Starting model:  CNRM-CM5\n",
      "Starting model:  bcc-csm1-1\n",
      "Starting model:  bcc-csm1-1-m\n",
      "Starting model:  GFDL-ESM2G\n",
      "Starting model:  GFDL-ESM2M\n",
      "Starting model:  GFDL-CM3\n",
      "Starting model:  EC-EARTH\n",
      "Starting model:  CESM1-WACCM\n",
      "Starting model:  CESM1-CAM5\n",
      "Starting model:  CESM1-FASTCHEM\n",
      "Starting model:  CESM1-BGC\n",
      "Starting model:  IPSL-CM5B-LR\n",
      "Starting model:  IPSL-CM5A-MR\n",
      "Starting model:  IPSL-CM5A-LR\n",
      "Starting model:  HadGEM2-ES\n",
      "Starting model:  HadGEM2-CC\n",
      "Starting model:  ACCESS1-3\n",
      "Starting model:  ACCESS1-0\n",
      "Starting model:  HadGEM2-AO\n",
      "Starting model:  GISS-E2-H\n",
      "Starting model:  GISS-E2-R\n",
      "Starting model:  GISS-E2-R-CC\n",
      "Starting model:  GISS-E2-H-CC\n",
      "Starting model:  CSIRO-Mk3-6-0\n",
      "Starting model:  CanESM2\n",
      "Starting model:  inmcm4\n",
      "Starting model:  CMCC-CMS\n",
      "Starting model:  CMCC-CM\n",
      "Starting model:  CMCC-CESM\n",
      "Starting model:  MIROC5\n",
      "Starting model:  NorESM1-ME\n",
      "Starting model:  NorESM1-M\n",
      "Starting model:  MPI-ESM-MR\n",
      "Starting model:  MPI-ESM-P\n",
      "Starting model:  MPI-ESM-LR\n",
      "Starting model:  MRI-CGCM3\n",
      "Starting model:  BNU-ESM\n",
      "Starting model:  MIROC-ESM\n",
      "Starting model:  MIROC-ESM-CHEM\n",
      "Starting model:  CCSM4\n",
      "Starting model:  FIO-ESM\n",
      "Starting model:  CNRM-CM5-2\n",
      "<xarray.DataArray 'tos' (model: 40, time: 1800, lat: 72, lon: 144)>\n",
      "dask.array<concatenate, shape=(40, 1800, 72, 144), dtype=float32, chunksize=(1, 60, 72, 144), chunktype=numpy.ndarray>\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 1850-01-01 1850-02-01 ... 1999-12-01\n",
      "  * lat      (lat) float64 -88.75 -86.25 -83.75 -81.25 ... 83.75 86.25 88.75\n",
      "  * lon      (lon) float64 1.25 3.75 6.25 8.75 11.25 ... 351.2 353.8 356.2 358.8\n",
      "  * model    (model) <U14 'CNRM-CM5' 'bcc-csm1-1' ... 'FIO-ESM' 'CNRM-CM5-2'\n",
      "Attributes:\n",
      "    standard_name:     sea_surface_temperature\n",
      "    long_name:         Sea Surface Temperature\n",
      "    comment:           \"this may differ from \"\"surface temperature\"\" in regio...\n",
      "    units:             K\n",
      "    original_name:     tos\n",
      "    original_units:    degC\n",
      "    history:           2011-10-10T21:09:38Z altered by CMOR: Converted units ...\n",
      "    cell_methods:      time: mean\n",
      "    cell_measures:     area: areacello\n",
      "    associated_files:  baseURL: http://cmip-pcmdi.llnl.gov/CMIP5/dataLocation...\n",
      "    regrid_method:     bilinear\n"
     ]
    }
   ],
   "source": [
    "def ingest_and_process(\n",
    "    output_grid: np.ndarray,\n",
    "    var: str = \"tos\", \n",
    "    cmipTable: str =\"Omon\", \n",
    "    era: str = \"CMIP6\",\n",
    "    testing: bool = False,\n",
    "    calc_anoms: bool = False\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Ingests all the data from the CMIP piControl experiment. \n",
    "    Optionally remove the seasonal cycle and detrend the data, regrid to a commond 2.5 x 2.5 degree grid and return a new dataset\n",
    "\n",
    "    Returns:\n",
    "        xarray datasets with dimensions (model, time, lat, lon)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all the paths to the data\n",
    "    dpaths = xs.findPaths(\n",
    "        experiment=\"piControl\",\n",
    "        variable=var,\n",
    "        frequency=\"mon\",\n",
    "        cmipTable=cmipTable,\n",
    "        mip_era=era, \n",
    "        activity=\"CMIP\",\n",
    "    )\n",
    "    models =  xs.getGroupValues(dpaths, 'model')\n",
    "    dpaths = list(dpaths.keys())\n",
    "    \n",
    "    # Create an empty Dataset\n",
    "    ds = []\n",
    "    valid_models = []\n",
    "\n",
    "    for i, (model_path, model) in enumerate(zip(dpaths, models)):\n",
    "        try:\n",
    "            print(\"Starting model: \", model)\n",
    "            # Load data\n",
    "            da = xc.open_mfdataset(glob(model_path + \"/*.nc\")) #, parallel=True, chunks=\"auto\")\n",
    "\n",
    "            # Regrid Data\n",
    "            output = da.regridder.horizontal(var, output_grid, tool='xesmf', method='bilinear')\n",
    "\n",
    "            # Deseasonalize (no need to detrend piControl data, there should be no drift)\n",
    "            if calc_anoms:\n",
    "                output = output.temporal.departures(var, \"month\")\n",
    "\n",
    "            ntime, _, _ = output[var].shape\n",
    "\n",
    "            nmonths = 150*12\n",
    "            if ntime < nmonths:\n",
    "                continue\n",
    "\n",
    "            output = output[var][:nmonths]\n",
    "            time = np.arange(np.datetime64(\"1850-01\"), np.datetime64(\"1850-01\") + np.timedelta64(nmonths, 'M'), dtype=\"datetime64[M]\")\n",
    "            output[\"time\"] = time\n",
    "            ds.append(output)\n",
    "            valid_models.append(model)\n",
    "\n",
    "            # Only load one model if testing\n",
    "            if testing:\n",
    "                _, axes = plt.subplots(ncols=2, figsize=(16, 4))\n",
    "                da[var].isel(time=0).plot(ax=axes[0])\n",
    "                axes[0].set_title('Input data')\n",
    "                output.isel(time=0).plot(ax=axes[1])\n",
    "                axes[1].set_title('Output data')\n",
    "                plt.tight_layout()\n",
    "\n",
    "                if i == 1:\n",
    "                    break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Model failed: \", model, e)\n",
    "            continue\n",
    "\n",
    "    ds = xr.concat(ds, dim='model')\n",
    "    ds.coords['model'] = list(valid_models)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def collect_data():\n",
    "    \"\"\"\n",
    "    Iterate through all the variables and eras and save the data\n",
    "    \"\"\"\n",
    "\n",
    "    # Define Constants\n",
    "    eras = [\"CMIP5\"] #, \"CMIP5\"]\n",
    "    variables = [\"tos\"] # ,\"rsutcs\", \"rsut\"] # tos == sea surface temperature\n",
    "    calc_anoms = False\n",
    "\n",
    "    # Create output grid\n",
    "    lat = np.arange(-88.75, 90, 2.5)\n",
    "    lon = np.arange(1.25, 360, 2.5)\n",
    "    output_grid = xc.create_grid(lat, lon)\n",
    "\n",
    "    for era in eras: \n",
    "        print(\"Starting era: \", era)\n",
    "        for var in variables:\n",
    "            print(\"Starting variable: \", var)\n",
    "\n",
    "            if var == \"tos\": \n",
    "                table = \"Omon\"\n",
    "            else: \n",
    "                table = \"Amon\"\n",
    "\n",
    "            ds = ingest_and_process(\n",
    "                var=var,\n",
    "                cmipTable=table,\n",
    "                era=era,\n",
    "                testing=False,\n",
    "                output_grid=output_grid,\n",
    "                calc_anoms=False\n",
    "            )\n",
    "\n",
    "            print(ds)\n",
    "            if calc_anoms:\n",
    "                ds.to_netcdf(f\"/data/{var}_mon_1850-2100_anoms_{era}_piControl.nc\")\n",
    "            else: \n",
    "                ds.to_netcdf(f\"/data/{var}_mon_1850-2100_{era}_piControl.nc\")\n",
    "                \n",
    "\n",
    "        break\n",
    "\n",
    "collect_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading _cmip6\n",
      "Loading _cmip5\n"
     ]
    }
   ],
   "source": [
    "def calculate_swcre(rsutcs: xr.Dataset, rsut: xr.Dataset, save: bool = False, save_name: str = \"\") -> Tuple[xr.Dataset, xr.Dataset]:\n",
    "    \"\"\"\n",
    "    Calculates the shortwave cloud radiative effect as the difference between the TOA SW clear-sky flux and the TOA SW all-sky flux\n",
    "\n",
    "    swcre = rsutcs - rsut\n",
    "    swcre_anoms = swcre - swcre_climatology\n",
    "\n",
    "    Args:\n",
    "        rsutcs (xr.Dataset): TOA clear-sky upward SW flux\n",
    "        rsut (xr.Dataset): TOA all-sky upward SW flux\n",
    "        save (bool, optional): Defaults to False\n",
    "        save_name (str, optional): Defaults to \"\".\n",
    "\n",
    "    Returns:\n",
    "        swcre (xr.Dataset): dimensions (model, time, lat, lon)\n",
    "        swcre anoms (xr.Dataset): dimensions (model, time, lat, lon)\n",
    "    \"\"\"\n",
    "    if not save: \n",
    "        print(f\"Loading {save_name}\")\n",
    "        swcre = xc.open_dataset(f\"data/swcre{save_name}_monthly_1850-2000.nc\", chunks=\"auto\")\n",
    "        swcre_anoms = xc.open_dataset(f\"data/swcre{save_name}_anoms_monthly_1850-2000.nc\", chunks=\"auto\")\n",
    "        return swcre, swcre_anoms \n",
    "\n",
    "    else:\n",
    "        # Select common models\n",
    "        common_models = list(set(rsutcs[\"model\"].values) & set(rsut[\"model\"].values))\n",
    "        rsutcs = rsutcs.sel(model=common_models)\n",
    "        rsut = rsut.sel(model=common_models)\n",
    "        # Calculate SWCRE\n",
    "        swcre = rsutcs[\"rsutcs\"] - rsut[\"rsut\"]\n",
    "        swcre = swcre.rename(\"swcre\").to_dataset()\n",
    "        # Set time bounds\n",
    "        swcre[\"time_bnds\"] = rsut[\"time_bnds\"]\n",
    "        # Calculate SWCRE anomalies\n",
    "        swcre_anoms = swcre.temporal.departures(\"swcre\", \"month\")\n",
    "        swcre_anoms = swcre_anoms.rename({\"swcre\": \"swcre_anoms\"})\n",
    "\n",
    "        print(\"Saving data\")\n",
    "        swcre.to_netcdf(f\"data/swcre{save_name}_monthly_1850-2000.nc\")\n",
    "        swcre_anoms.to_netcdf(f\"data/swcre{save_name}_anoms_monthly_1850-2000.nc\")\n",
    "\n",
    "    return swcre, swcre_anoms\n",
    "\n",
    "# Set save or load\n",
    "SAVE = False\n",
    "\n",
    "if SAVE: \n",
    "    # Load data\n",
    "    rsut_cmip5 = xc.open_dataset(\"data/rsut_mon_1850-2100_CMIP5_piControl.nc\")\n",
    "    rsut_cmip6 = xc.open_dataset(\"data/rsut_mon_1850-2100_CMIP6_piControl.nc\")\n",
    "    rsutcs_cmip6 = xc.open_dataset(\"data/rsutcs_mon_1850-2100_CMIP6_piControl.nc\")\n",
    "    rsutcs_cmip5 = xc.open_dataset(\"data/rsutcs_mon_1850-2100_CMIP5_piControl.nc\")\n",
    "else:\n",
    "    # Filler Data\n",
    "    rsut_cmip5, rsut_cmip6, rsutcs_cmip5, rsutcs_cmip6 = None, None, None, None\n",
    "\n",
    "# Calculate SWCRE, SWCRE anomalies, and save\n",
    "swcre_cmi6, swcre_anoms_cmip6 = calculate_swcre(rsutcs_cmip6, rsut_cmip6, save=SAVE, save_name=\"_cmip6\")\n",
    "swcre_cmip5, swcre_anoms_cmip5 = calculate_swcre(rsutcs_cmip5, rsut_cmip5, save=SAVE, save_name=\"_cmip5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_swcf(tos: xr.Dataset, swcre: xr.Dataset, save: bool = False, save_name: str = \"\") -> xr.Dataset:\n",
    "    \"\"\"Calculate the shortwave cloud feedback (swcf)\n",
    "\n",
    "    Definition 1:\n",
    "    swcf = dR_swcre / dSST (Wm^-2/K)\n",
    "\n",
    "    Definition 2:\n",
    "    swcre_anoms = swcf * SST_anoms + b\n",
    "\n",
    "    Args:\n",
    "        tos (xr.Dataset): monthly sst anomalies\n",
    "        swcre (xr.Dataset): monthly swcre anomalies\n",
    "        save (bool, optional): Defaults to False.\n",
    "        save_name (str, optional): Defaults to \"\".\n",
    "\n",
    "    Returns:\n",
    "        swcf (xr.Dataset): dimensions (model, time, lat, lon)\n",
    "    \"\"\"\n",
    "    if save: \n",
    "        # Rechunk along time dimension\n",
    "        tos = tos.chunk({'time': -1})\n",
    "        swcre = swcre.chunk({'time': -1})\n",
    "\n",
    "        # Calculate the correlation coefficient\n",
    "        swcf = xscore.linslope(tos, swcre, dim='time')\n",
    "        swcf.to_netcdf(f\"data/swcf_{save_name}_monthly_1850-2000.nc\")\n",
    "    else: \n",
    "        swcf = xr.open_dataarray(f\"data/swcf_{save_name}_monthly_1850-2000.nc\", chunks=\"auto\")\n",
    "    return swcf\n",
    "\n",
    "# Set save or load\n",
    "SAVE = False\n",
    "# Load tos\n",
    "tos_cmip6 = xc.open_dataset(\"data/tos_mon_1850-2100_CMIP6_piControl.nc\", chunks=\"auto\")\n",
    "tos_cmip5 = xc.open_dataset(\"data/tos_mon_1850-2100_CMIP5_piControl.nc\", chunks=\"auto\")\n",
    "# Calculate tos anomalies\n",
    "tos_anoms_cmip6 = tos_cmip6.temporal.departures(\"tos\", \"month\")\n",
    "tos_anoms_cmip5 = tos_cmip5.temporal.departures(\"tos\", \"month\")\n",
    "# Calculate SWCF\n",
    "swcf_cmip6 = calculate_swcf(tos_anoms_cmip6[\"tos\"], swcre_anoms_cmip6[\"swcre_anoms\"], save=SAVE, save_name=\"cmip6\")\n",
    "swcf_cmip5 = calculate_swcf(tos_anoms_cmip5[\"tos\"], swcre_anoms_cmip5[\"swcre_anoms\"], save=SAVE, save_name=\"cmip5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_plot(data, lon, lat, cmap, title=\"\"):\n",
    "    # plot map of global data with central longitude 180\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson(central_longitude=180))\n",
    "    ax1.contourf(\n",
    "        lon, lat, data,\n",
    "        transform=ccrs.PlateCarree(), cmap=cmap\n",
    "    )\n",
    "    gl = ax1.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=2, color='gray', alpha=0.5, linestyle='--')\n",
    "    ax1.coastlines()\n",
    "    ax1.set_global()\n",
    "    ax1.set_title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def calculate_rolling_gradient(data: xr.DataArray, window: int = 12*30, step: int = 12) -> np.array:\n",
    "    \"\"\"Calculate the rolling gradient of a dataset\n",
    "\n",
    "    Args:\n",
    "        data (xr.DataArray): _description_\n",
    "        window (int, optional): _description_. Defaults to 120*30.\n",
    "        step (int, optional): _description_. Defaults to 12.\n",
    "\n",
    "    Returns:\n",
    "        np.array: _description_\n",
    "    \"\"\"\n",
    "    grads = np.zeros((data.model.size, len(data.time) - window))\n",
    "    grads.fill(np.nan)\n",
    "    time_idx = xr.DataArray(np.arange(window), dims=\"time\")\n",
    "    for i in range(0, len(data.time) - window, step):\n",
    "        grads[:,i] = xscore.linslope(time_idx, data.isel(time=slice(i, i+window)), dim='time', skipna=True).values\n",
    "\n",
    "    return grads\n",
    "\n",
    "def get_east_west(ds: xr.Dataset) -> Tuple[xr.Dataset, xr.Dataset]:\n",
    "    return (\n",
    "        ds.sel(lon=slice(80, 160), lat=slice(-7, 7)), # West pacific\n",
    "        ds.sel(lon=slice(-160, -80), lat=slice(-7, 7)) # East pacific\n",
    "    )\n",
    "\n",
    "def calculate_west_east_gradient(ds: xr.Dataset, var: str) -> Tuple[xr.DataArray, xr.DataArray, xr.DataArray]:\n",
    "    ds = xc.swap_lon_axis(ds, to=(-180, 180))\n",
    "\n",
    "    ds_west, ds_east = get_east_west(ds)\n",
    "\n",
    "    ds_west = ds_west.spatial.average(var)[var]\n",
    "    ds_east = ds_east.spatial.average(var)[var]\n",
    "\n",
    "    # Calculate gradient\n",
    "    return ds_west, ds_east, ds_west - ds_east\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SWCF Values for West and East Pacific\n",
    "swcf_cmip6_ds = swcf_cmip6.rename(\"swcf\").to_dataset().bounds.add_bounds(\"X\")\n",
    "swcf_cmip6_ds = swcf_cmip6_ds.bounds.add_bounds(\"Y\")\n",
    "swcf_cmip5_ds = swcf_cmip5.rename(\"swcf\").to_dataset().bounds.add_bounds(\"X\")\n",
    "swcf_cmip5_ds = swcf_cmip5_ds.bounds.add_bounds(\"Y\")\n",
    "\n",
    "swcf_west_cmip6, swcf_east_cmip6, _ = calculate_west_east_gradient(ds=swcf_cmip6_ds, var=\"swcf\")\n",
    "swcf_west_cmip5, swcf_east_cmip5, _ = calculate_west_east_gradient(ds=swcf_cmip5_ds, var=\"swcf\")\n",
    "# Save to netcdf\n",
    "swcf_west_cmip5.to_netcdf(\"data/swcf_west_cmip5.nc\")\n",
    "swcf_west_cmip6.to_netcdf(\"data/swcf_west_cmip6.nc\")\n",
    "swcf_east_cmip5.to_netcdf(\"data/swcf_east_cmip5.nc\")\n",
    "swcf_east_cmip6.to_netcdf(\"data/swcf_east_cmip6.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Rolling 30-year trend of SST gradient\n",
    "tos_west_cmip6, tos_east_cmip6, tos_grad_cmip6 = calculate_west_east_gradient(ds=tos_cmip6, var=\"tos\")\n",
    "tos_west_cmip5, tos_east_cmip5, tos_grad_cmip5 = calculate_west_east_gradient(ds=tos_cmip5, var=\"tos\")\n",
    "\n",
    "tos_grad_cmip5 = tos_grad_cmip5.chunk({\"time\": -1})\n",
    "tos_grad_cmip6 = tos_grad_cmip6.chunk({\"time\": -1})\n",
    "tos_grad_trend_cmip6 = calculate_rolling_gradient(data=tos_grad_cmip6, window=30*12, step=12)\n",
    "tos_grad_trend_cmip5 = calculate_rolling_gradient(data=tos_grad_cmip5, window=30*12, step=12)\n",
    "\n",
    "tos_grad_trend_cmip6.to_netcdf(\"data/tos_grad_trend_cmip6.nc\")\n",
    "tos_grad_trend_cmip5.to_netcdf(\"data/tos_grad_trend_cmip5.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(tos_grad_trend_cmip6[~np.isnan(tos_grad_trend_cmip6)])\n",
    "# tos_grad_var_cmip6 = np.std(tos_grad_trend_cmip6, axis=1)\n",
    "# tos_grad_var_cmip5 = np.std(tos_grad_trend_cmip5, axis=1)\n",
    "# print(tos_grad_var_cmip6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
