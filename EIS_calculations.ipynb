{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook that will calculate EIS (Wood and Bretherton 2008) for all CMIP6, CMIP5, and observational data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xcdat as xc\n",
    "import xarray as xr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/home/espinosa10/tropical_pacific_clouds/data/piControl/ta700_mon_1850-2100_CMIP5_piControl.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/file_manager.py:209\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key]\n\u001b[1;32m    210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/lru_cache.py:55\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m---> 55\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache[key]\n\u001b[1;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/home/espinosa10/tropical_pacific_clouds/data/piControl/ta700_mon_1850-2100_CMIP5_piControl.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '4577f93d-d7fd-4ac2-ac33-219bc4317c44']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m ps \u001b[39m=\u001b[39m xc\u001b[39m.\u001b[39mopen_dataset(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/piControl/psl_mon_1850-2100_\u001b[39m\u001b[39m{\u001b[39;00mERA\u001b[39m}\u001b[39;00m\u001b[39m_piControl.nc\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mpsl\n\u001b[1;32m      9\u001b[0m t2m \u001b[39m=\u001b[39m xc\u001b[39m.\u001b[39mopen_dataset(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/piControl/tas_mon_1850-2100_\u001b[39m\u001b[39m{\u001b[39;00mERA\u001b[39m}\u001b[39;00m\u001b[39m_piControl.nc\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mtas \n\u001b[0;32m---> 10\u001b[0m ta700 \u001b[39m=\u001b[39m xc\u001b[39m.\u001b[39mopen_dataset(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/piControl/ta700_mon_1850-2100_\u001b[39m\u001b[39m{\u001b[39;00mERA\u001b[39m}\u001b[39;00m\u001b[39m_piControl.nc\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mta\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mplev\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39m# LOL there is better way to do this but I don't want to figure it out atm\u001b[39;00m\n\u001b[1;32m     13\u001b[0m hur2m, ps \u001b[39m=\u001b[39m get_shared_models(hur2m, ps)\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xcdat/dataset.py:103\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(path, data_var, add_bounds, decode_times, center_times, lon_orient, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen_dataset\u001b[39m(\n\u001b[1;32m     41\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m     42\u001b[0m     data_var: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m     48\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m xr\u001b[39m.\u001b[39mDataset:\n\u001b[1;32m     49\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Wraps ``xarray.open_dataset()`` with post-processing options.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39m    .. [1] https://xarray.pydata.org/en/stable/generated/xarray.open_dataset.html\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     ds \u001b[39m=\u001b[39m xr\u001b[39m.\u001b[39mopen_dataset(path, decode_times\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m decode_times:\n\u001b[1;32m    106\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/api.py:539\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m decoders \u001b[39m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    528\u001b[0m     decode_cf,\n\u001b[1;32m    529\u001b[0m     open_backend_dataset_parameters\u001b[39m=\u001b[39mbackend\u001b[39m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    535\u001b[0m     decode_coords\u001b[39m=\u001b[39mdecode_coords,\n\u001b[1;32m    536\u001b[0m )\n\u001b[1;32m    538\u001b[0m overwrite_encoded_chunks \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39moverwrite_encoded_chunks\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 539\u001b[0m backend_ds \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mopen_dataset(\n\u001b[1;32m    540\u001b[0m     filename_or_obj,\n\u001b[1;32m    541\u001b[0m     drop_variables\u001b[39m=\u001b[39mdrop_variables,\n\u001b[1;32m    542\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecoders,\n\u001b[1;32m    543\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    544\u001b[0m )\n\u001b[1;32m    545\u001b[0m ds \u001b[39m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    546\u001b[0m     backend_ds,\n\u001b[1;32m    547\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    556\u001b[0m )\n\u001b[1;32m    557\u001b[0m \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:572\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen_dataset\u001b[39m(\n\u001b[1;32m    552\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    553\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    568\u001b[0m     autoclose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m ):\n\u001b[1;32m    571\u001b[0m     filename_or_obj \u001b[39m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 572\u001b[0m     store \u001b[39m=\u001b[39m NetCDF4DataStore\u001b[39m.\u001b[39mopen(\n\u001b[1;32m    573\u001b[0m         filename_or_obj,\n\u001b[1;32m    574\u001b[0m         mode\u001b[39m=\u001b[39mmode,\n\u001b[1;32m    575\u001b[0m         \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m,\n\u001b[1;32m    576\u001b[0m         group\u001b[39m=\u001b[39mgroup,\n\u001b[1;32m    577\u001b[0m         clobber\u001b[39m=\u001b[39mclobber,\n\u001b[1;32m    578\u001b[0m         diskless\u001b[39m=\u001b[39mdiskless,\n\u001b[1;32m    579\u001b[0m         persist\u001b[39m=\u001b[39mpersist,\n\u001b[1;32m    580\u001b[0m         lock\u001b[39m=\u001b[39mlock,\n\u001b[1;32m    581\u001b[0m         autoclose\u001b[39m=\u001b[39mautoclose,\n\u001b[1;32m    582\u001b[0m     )\n\u001b[1;32m    584\u001b[0m     store_entrypoint \u001b[39m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    585\u001b[0m     \u001b[39mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:376\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    370\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    371\u001b[0m     clobber\u001b[39m=\u001b[39mclobber, diskless\u001b[39m=\u001b[39mdiskless, persist\u001b[39m=\u001b[39mpersist, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m\n\u001b[1;32m    372\u001b[0m )\n\u001b[1;32m    373\u001b[0m manager \u001b[39m=\u001b[39m CachingFileManager(\n\u001b[1;32m    374\u001b[0m     netCDF4\u001b[39m.\u001b[39mDataset, filename, mode\u001b[39m=\u001b[39mmode, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    375\u001b[0m )\n\u001b[0;32m--> 376\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m(manager, group\u001b[39m=\u001b[39mgroup, mode\u001b[39m=\u001b[39mmode, lock\u001b[39m=\u001b[39mlock, autoclose\u001b[39m=\u001b[39mautoclose)\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:323\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group \u001b[39m=\u001b[39m group\n\u001b[1;32m    322\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m mode\n\u001b[0;32m--> 323\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mds\u001b[39m.\u001b[39mdata_model\n\u001b[1;32m    324\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filename \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mds\u001b[39m.\u001b[39mfilepath()\n\u001b[1;32m    325\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_remote \u001b[39m=\u001b[39m is_remote_uri(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filename)\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:385\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    384\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mds\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 385\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_acquire()\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:379\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_acquire\u001b[39m(\u001b[39mself\u001b[39m, needs_lock\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 379\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_manager\u001b[39m.\u001b[39macquire_context(needs_lock) \u001b[39mas\u001b[39;00m root:\n\u001b[1;32m    380\u001b[0m         ds \u001b[39m=\u001b[39m _nc4_require_group(root, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_group, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode)\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/file_manager.py:197\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m@contextlib\u001b[39m\u001b[39m.\u001b[39mcontextmanager\n\u001b[1;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39macquire_context\u001b[39m(\u001b[39mself\u001b[39m, needs_lock\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    196\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     file, cached \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_acquire_with_cache_info(needs_lock)\n\u001b[1;32m    198\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m         \u001b[39myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/backends/file_manager.py:215\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    213\u001b[0m     kwargs \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    214\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode\n\u001b[0;32m--> 215\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_opener(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    217\u001b[0m     \u001b[39m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2463\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2026\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/home/espinosa10/tropical_pacific_clouds/data/piControl/ta700_mon_1850-2100_CMIP5_piControl.nc'"
     ]
    }
   ],
   "source": [
    "ERA = \"CMIP5\"\n",
    "\n",
    "def get_shared_models(ds1, ds2):\n",
    "    shared_models = list(set(ds1.model.values).intersection(set(ds2.model.values)))\n",
    "    return ds1.sel(model=shared_models), ds2.sel(model=shared_models)\n",
    "\n",
    "hur2m = xc.open_dataset(f\"data/piControl/hur_mon_1850-2100_{ERA}_piControl.nc\").drop('plev')\n",
    "ps = xc.open_dataset(f\"data/piControl/psl_mon_1850-2100_{ERA}_piControl.nc\").psl\n",
    "t2m = xc.open_dataset(f\"data/piControl/tas_mon_1850-2100_{ERA}_piControl.nc\").tas \n",
    "ta700 = xc.open_dataset(f\"data/piControl/ta700_mon_1850-2100_{ERA}_piControl.nc\").ta.drop('plev')\n",
    "\n",
    "# LOL there is better way to do this but I don't want to figure it out atm\n",
    "hur2m, ps = get_shared_models(hur2m, ps)\n",
    "hur2m, ta700 = get_shared_models(hur2m, ta700)\n",
    "hur2m, t2m = get_shared_models(hur2m, t2m)\n",
    "hur2m, ps = get_shared_models(hur2m, ps)\n",
    "hur2m, ta700 = get_shared_models(hur2m, ta700)\n",
    "\n",
    "data = xr.merge([hur2m, ps, ta700, t2m])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Observations\n",
    "# d2m = xr.open_dataset(\"data/obs/d2m_mon_ERA5_197901-202212.nc\")\n",
    "# ps = xc.open_dataset(\"data/obs/psl_mon_ERA5_197901-202212.nc\").msl\n",
    "# ta700 = xc.open_dataset(\"data/obs/ta700_mon_ERA5_197901-202212.nc\").t\n",
    "# t2m = xr.open_dataset(\"data/obs/t2m_mon_ERA5_197901-202212.nc\")\n",
    "\n",
    "# # Subset time\n",
    "# d2m = d2m.isel(time=np.arange(len(ps.time))).drop(\"experimentVersionNumber\")\n",
    "# t2m = t2m.isel(time=np.arange(len(ps.time))).drop(\"experimentVersionNumber\")\n",
    "# d2m[\"time\"] = ps[\"time\"]\n",
    "# t2m[\"time\"] = ps[\"time\"]\n",
    "\n",
    "# # ds = xc.swap_lon_axis(ds, to=(-180, 180))\n",
    "\n",
    "# # # Regrid d2m and t2m\n",
    "# output_grid = xc.create_grid(ps.latitude.values, ps.longitude.values)\n",
    "# d2m = d2m.regridder.horizontal(\"d2m\", output_grid, tool='xesmf', method='bilinear')[\"d2m\"]\n",
    "# t2m = t2m.regridder.horizontal(\"t2m\", output_grid, tool='xesmf', method='bilinear')[\"t2m\"]\n",
    "# d2m = d2m.rename({\"lon\": \"longitude\", \"lat\": \"latitude\"})\n",
    "# t2m = t2m.rename({\"lon\": \"longitude\", \"lat\": \"latitude\"})\n",
    "\n",
    "# # Calculate 2m specific humidity from d2m, ps, and t2m\n",
    "# hur2m=calculate_wvsat(d2m,ps/100)/calculate_wvsat(t2m,ps/100)*100 \n",
    "# hur2m=hur2m.where(hur2m<=100.,100.)\n",
    "\n",
    "# # Rename and Merge\n",
    "# hur2m = hur2m.rename(\"hur\")\n",
    "# ta700 = ta700.rename(\"ta\")\n",
    "# t2m = t2m.rename(\"tas\")\n",
    "# ps = ps.rename(\"psl\")\n",
    "# data = xr.merge([hur2m, ps, ta700, t2m])\n",
    "# data = data.drop(\"realization\")\n",
    "# data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate EIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wvsat(t,p):\n",
    "\t\"\"\"\n",
    "    wvsat(t): return water vapor saturation mixing ratio (g/kg)\n",
    "\tover liquid for t > 273 K and over ice for t < 273 K\n",
    "    t is an xarray DataArray, which includes pressures on coordinate 'level'\"\"\"\n",
    "\n",
    "    # air > freezing\n",
    "    # Source Hyland, R. W. and A. Wexler, Formulations for the Thermodynamic Properties of the saturated \n",
    "    # Phases of H2O from 173.15K to 473.15K, ASHRAE Trans, 89(2A), 500-519, 1983.\n",
    "\tp1 = np.exp(  -0.58002206e4 / t + 0.13914993e1 - 0.48640239e-1 * t \n",
    "\t+ 0.41764768e-4 * t**2. - 0.14452093e-7 * t**3. \n",
    "\t+ 0.65459673e1 * np.log(t) ) / 100.\n",
    "\n",
    "# Source : Goff-Gratch, Smithsonian Meteorological Tables, 5th edition, p. 350, 1984\n",
    "\tei0\t   = 6.1071\t\t  # mbar\n",
    "\tT0\t   = 273.16\t\t  # freezing point in K\n",
    "\tp2 = 10.**(-9.09718 * (T0 / t - 1.) - 3.56654 * np.log10(T0 / t) + 0.876793 * (1. - t / T0) + np.log10(ei0))\n",
    "    \n",
    "\tPsat=t*0\n",
    "\tPsat=Psat.where(t < 273,p2)\n",
    "\tPsat=Psat.where(t > 273,p1)\n",
    "\n",
    "\treturn Psat/p*18/29.  # return to kg/kg\n",
    "\n",
    "def calculate_eis(psfc: xr.DataArray, RHsfc: xr.DataArray, Tsfc: xr.DataArray, T700: xr.DataArray, testing: bool = True) -> xr.Dataset:\n",
    "    \"\"\"Calculate Estimated Inversion Strength (EIS) and Lower Tropospheric Stability (LTS)\n",
    "        from data using Mark Zelinka and Li. Wei's method and defined in WOOD AND BRETHERTON 2006\n",
    "\n",
    "    \n",
    "    Args:\n",
    "        psfc (xr.DataArray): Surface Pressure (Pa)\n",
    "        RHsfc (xr.DataArray): Surface Relative Humidity (%)\n",
    "        Tsfc (xr.DataArray): Surface Temperature (K)\n",
    "        T700 (xr.DataArray): 700 hPa Temperature (K)\n",
    "\n",
    "    Returns:\n",
    "        EIS (xr.Dataset): dimensions (model, time, lat, lon) (K)\n",
    "        LTS (xr.Dataset): dimensions (model, time, lat, lon) (K)\n",
    "    \"\"\"\n",
    "    if testing: \n",
    "        print(\"Testing\")\n",
    "        psfc = psfc.isel(time=0)\n",
    "        # RHsfc = RHsfc.isel(time=0)\n",
    "        Tsfc = Tsfc.isel(time=0)\n",
    "        T700 = T700.isel(time=0)\n",
    "\n",
    "    g   = 9.81\n",
    "    Rd  = 287.04\n",
    "    Rv  = 461.50\n",
    "    cpd = 1013.\n",
    "    Lv  = 2.5e6\n",
    "\n",
    "    LTS=T700*(700./1000)**(-2./7)-Tsfc*(psfc/100./1000.)**(-2./7)\n",
    "    \n",
    "    LTS=LTS.where(psfc>=70000,0.)\n",
    "    LTS=LTS.where(~np.isnan(LTS),0.)\n",
    "    LTS=LTS.where(LTS>=0.,0.)\n",
    "    \n",
    "    z700 = (Rd*Tsfc/g)*np.log(psfc/70000.)\n",
    "    zlcl = (20+(Tsfc-273)/5.)*(100-RHsfc)  # meters; hur0 should technically be hurs\n",
    "\n",
    "    p850 = 850.\n",
    "    t850 = (Tsfc+T700)/2. # consistent with Wood and Bretherton\n",
    "\n",
    "    #     qs850 = es_calc(t850-273.15)/(p850*100)*18/29. # temperature (K), pressure (hPa), sat mixing ratio (kg water/kg air)\n",
    "    qs850 = calculate_wvsat(t850,np.array([p850])) # temperature (K), pressure (hPa), sat mixing ratio (kg water/kg air)\n",
    "    gamma = g/cpd*(1-(1+Lv*qs850/Rd/t850)/(1+Lv**2*qs850/cpd/Rv/t850**2))\n",
    "    \n",
    "    EIS = LTS-gamma*(z700-zlcl)\n",
    "    \n",
    "    EIS = EIS.where(psfc>=70000,0.)\n",
    "    EIS = EIS.where(~np.isnan(EIS),0.)\n",
    "    return EIS, LTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/espinosa10/miniconda3/envs/swc/lib/python3.11/site-packages/xarray/core/computation.py:771: RuntimeWarning: divide by zero encountered in log\n",
      "  result_data = func(*input_data)\n"
     ]
    }
   ],
   "source": [
    "EIS, LTS = calculate_eis(psfc=data.psl, RHsfc=80, Tsfc=data.tas, T700=data.ta, testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIS = EIS.rename(\"eis\").to_dataset()\n",
    "EIS.to_netcdf(f\"data/piControl/EIS_mon_1850-2000_{ERA}_piControl_update.nc\")\n",
    "# EIS.to_netcdf(f\"data/obs/EIS_mon_197901-202212_obs.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIS = EIS.bounds.add_bounds(\"T\")\n",
    "EIS_anoms = EIS.temporal.departures(\"eis\", \"month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "EIS_anoms.to_netcdf(f\"data/piControl/EIS_anoms_mon_1850-2000_{ERA}_piControl_update.nc\")\n",
    "# EIS_anoms.to_netcdf(f\"data/obs/EIS_anoms_mon_197901-202212_obs.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_plot_patterns(data, lon, lat, cmap, title=\"\", levels=np.arange(-1.5, 1.5, .1)):\n",
    "    # plot map of global data with central longitude 180\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax1 = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=180))\n",
    "    img = ax1.contourf(\n",
    "        lon, lat, data,\n",
    "        transform=ccrs.PlateCarree(), cmap=cmap,\n",
    "        extend=\"both\",\n",
    "        levels=levels,\n",
    "    )\n",
    "    ax1.set_extent([-180, 180, -30, 30], crs=ccrs.PlateCarree())\n",
    "    gl = ax1.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=2, color='gray', alpha=0.5, linestyle='--')\n",
    "        \n",
    "    ax1.coastlines()\n",
    "    ax1.set_global()\n",
    "    ax1.set_title(title)\n",
    "    # Add a horizontal colorbar\n",
    "    cbar = plt.colorbar(img, orientation='horizontal')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_plot_patterns(EIS.mean([\"model\", \"time\"]), EIS.lon, EIS.lat, cmap=\"RdBu_r\", levels=np.arange(-5, 5.1, .1), title=\"EIS (K)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
